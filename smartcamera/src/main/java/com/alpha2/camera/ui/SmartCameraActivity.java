package com.alpha2.camera.ui;import android.app.Activity;import android.content.BroadcastReceiver;import android.content.Context;import android.content.Intent;import android.content.IntentFilter;import android.content.res.AssetFileDescriptor;import android.content.res.AssetManager;import android.graphics.Rect;import android.media.MediaPlayer;import android.os.Bundle;import android.os.Handler;import android.os.Message;import android.text.TextUtils;import android.util.Log;import com.alpha2.camera.CameraPreview;import com.alpha2.camera.arcsoft.dam.ArcsoftDetectionRectF;import com.alpha2.camera.arcsoft.dam.RectfVector;import com.alpha2.camera.utils.ConfigurationJsonUtil;import com.alpha2.camera.utils.RobotValues.PoseState;import com.alpha2.camera.utils.StorageUtil;import com.alpha2.camera.utils.StringUtil;import com.arcsoft.api.ArcConstants;import com.arcsoft.api.ArcDetectResult;import com.arcsoft.api.ArcSoftApi;import com.arcsoft.api.OnDetectCallback;import com.ubtech.smartcamera.R;import com.ubtechinc.alpha.model.StaticValue;import com.ubtechinc.alpha.sdk.AlphaRobotApi;import com.ubtechinc.alpha.sdk.led.LedBright;import com.ubtechinc.alpha.sdk.led.LedColor;import com.ubtechinc.alpha.sdk.led.LedRobotApi;import com.ubtechinc.alpha.sdk.motion.MotionRobotApi;import com.ubtechinc.alpha.sdk.speech.SpeechRobotApi;import com.ubtechinc.alpha.serverlibutil.interfaces.LedOperationResultListener;import com.ubtechinc.alpha.serverlibutil.interfaces.SpeechTtsListener;import org.json.JSONException;import org.json.JSONObject;import java.io.IOException;import java.nio.ByteBuffer;import java.util.Random;import java.util.Timer;import java.util.TimerTask;/** * developed by brian.li */public class SmartCameraActivity extends Activity implements  FaceViewCallBack {    private static final String TAG ="SmartCameraActivity";    private ArcSoftApi mArcApi;    private AlphaRobotApi mRobot;    private int[] dataAngle;    private short single_time = 900;  //times less is faster, more is slow    private PoseState mPoseState = PoseState.IDLE;    private Context mContext;    public static final String ALPHA_SPEECH_DIRECTION = "com.ubtechinc.services.SPEECH_DIRECTION";    public static  final int BASE_NUMBER = 500;    public static final int STORAGE_SPACE_LESS = BASE_NUMBER - 1;    public static final int ENTER_PHOTO_MODE = BASE_NUMBER + 0;    public static final int SOUND_DETECTION = BASE_NUMBER + 1;    public static final int FINDING_SOUND = BASE_NUMBER + 2;    public static final int NOT_FINDING_SOUND = BASE_NUMBER + 3;    public static final int FACE_DETECTION = BASE_NUMBER + 4;    public static final int FINDING_FACE = BASE_NUMBER + 5;    public static final int NOT_FINDING_FACE = BASE_NUMBER + 6;    public static final int START_TAKE_PHOTO = BASE_NUMBER + 7;    public static final int PLAY_CAMERA_SOUND = BASE_NUMBER + 8;    public static final int SUCCESS_TAKE_PHOTO = BASE_NUMBER + 9;    public static final int EXIT_PHOTO_MODE = BASE_NUMBER + 10;    public static final int KILL_SELF=BASE_NUMBER+11;    public static final int EXIT_PHOTO_MODE_HITHEAD=BASE_NUMBER+12;    public static final int EXIT_SMART_CAMERA=BASE_NUMBER+13;    public static final int BASE_NUMBER_NEXT = 600;    public static final int INIT_ANGLE = BASE_NUMBER_NEXT + 1;    public static final int FACE_HORIZONAL_ANGLE = BASE_NUMBER_NEXT + 2;    public static final int FACE_VERTICAL_ANGLE = BASE_NUMBER_NEXT + 3;    public static final int FACE_HORIZONAL_VERTICAL_ANGLE = BASE_NUMBER_NEXT + 4;    public static final String ALPHA_APP_MANAGE = "com.ubt.alpha2.app.manager";    public static final String ALPHA_TTS_HINT = "com.ubtechinc.robot.tts_hint_wakeup";    public static int status = STORAGE_SPACE_LESS;    private Timer mTimer = null;    private Timer mTimer1 = null;    private TimerTask mTimerTask = null;    private TimerTask mTimerTask1 = null;    private int mLastUserAngle = 75;    int find_sound_times = 0;    int find_face_times = 0;    int DETECT_SOUND_TIME = 5; //8x1000    int DETECT_FACE_TIME = 70; //20x1000    int confirm_times = 0;    private FaceView faceView;    private CameraPreview preview;    private String VERSION = "0.1.1";    private ConfigurationJsonUtil mConfigurationJsonUtil;    private static final String DEFAULT_ASR_LANGUAGE = "zh_cn";    private static final String DEFAULT_DEFAULT_APP = "com.ubtech.iflytekmix";    private static final String KEY_ASR_LANGUAGE = "asr_Language";    private static final String KEY_DEFAULT_APP = "default_App";    public static String mRobotLanguage = "zh_cn";    public static String defApp = "com.ubtech.iflytekmix";    private long currentTime;    public static Boolean STRIKE_HEAD=false;    public static final String UBTEK_KEY_BROADCAST = "com.ubtechinc.key";    public final static String EN = "en_us";    public final static String CN = "zh_cn";    /** head key press broadcast**/    public static final String UBTEK_KEY_VALUE = "key";    private SpeechRobotApi speechApi;    private MotionRobotApi motionRobotApi;    private LedRobotApi ledRobotApi;    @Override    protected void onCreate(Bundle savedInstanceState) {        Log.d("TAG", "onCreate Smart Camera VERSION1  " + VERSION);        super.onCreate(savedInstanceState);        setContentView(R.layout.activity_camera);        currentTime = System.currentTimeMillis()/1000;        Log.d(TAG, "onCreate Smart Camera VERSION 2 " + VERSION);        mContext = this;        Thread initLanguageEngine=new Thread(new Runnable() {            @Override            public void run() {                Log.d(TAG,"init Language engine beinning");                getStringResources();            }        });        initLanguageEngine.start();        Thread initViewEngine=new Thread(new Runnable() {            @Override            public void run() {                Log.d(TAG,"init View engine beinning");                initViews();            }        });        initViewEngine.start();       Thread initSpeechEngine=new Thread(new Runnable() {          @Override          public void run() {              Log.d(TAG,"init Speech engine beinning");              initRobot();              initOver();           }       });        initSpeechEngine.start();        Thread initFaceEngine=new Thread(new Runnable() {            @Override            public void run() {                Log.d(TAG,"init Face engine beinning");                initFaceEngine();            }        });        initFaceEngine.start();        IntentFilter myIntentFilter = new IntentFilter();        myIntentFilter.addAction(ALPHA_SPEECH_DIRECTION);        myIntentFilter.addAction(UBTEK_KEY_BROADCAST);        myIntentFilter.addAction(ALPHA_TTS_HINT);        myIntentFilter.addAction(StaticValue.ACTION_UBT_APP_EXIT);        mContext.registerReceiver(mSoundReceiver, myIntentFilter);    }    private boolean getStringResources() {        boolean isSuccess = true;        mConfigurationJsonUtil = new ConfigurationJsonUtil(getApplicationContext());        String info = mConfigurationJsonUtil.readConfigFile();        if (mConfigurationJsonUtil.isConfigFileExist()) {            if (TextUtils.isEmpty(info)) {                isSuccess = false;            } else {                JSONObject infoJson = null;                Log.d(TAG, "start=" + System.currentTimeMillis());                try {                    infoJson = new JSONObject(info);                    if (infoJson != null) {                        String asrLanguage = DEFAULT_ASR_LANGUAGE;                        try {                            asrLanguage = infoJson.getString(KEY_ASR_LANGUAGE);                            Log.i(TAG, "asrLanguage=" + asrLanguage);                        } catch (JSONException e) {                        }                        mRobotLanguage = asrLanguage;                        if (CN.equals(mRobotLanguage)) {                            StringUtil.setLanguage(mContext, CN);                        } else if (EN.equals(mRobotLanguage)) {                            StringUtil.setLanguage(mContext,EN);                        }                        String defaultApp = DEFAULT_DEFAULT_APP;                        try {                            defaultApp = infoJson.getString(KEY_DEFAULT_APP);                            Log.i(TAG, "defaultApp=" + defaultApp);                        } catch (JSONException e) {                        }                        defApp = defaultApp;                    } else {                        isSuccess = false;                        StringUtil.setLanguage(mContext,CN);                        mRobotLanguage = DEFAULT_ASR_LANGUAGE;                        defApp = DEFAULT_DEFAULT_APP;                    }                } catch (JSONException e) {                    e.printStackTrace();                }                Log.d(TAG, "end=" + System.currentTimeMillis());            }        }else {            StringUtil.setLanguage(mContext,CN);        }        return isSuccess;    }    @Override    protected void onStart() {        super.onStart();        Log.e(TAG, "onStart()");    }    @Override    protected void onResume() {        super.onResume();        Log.e(TAG, "onResume()");    }    @Override    protected void onStop() {        super.onStop();    }    @Override    protected void onDestroy() {        // TODO Auto-generated method stub        super.onDestroy();        Log.e("TAG", "onDestroy()");        if (mRobot != null){            mRobot.destroy();            mRobot=null;        }        if (mSoundReceiver != null)            unregisterReceiver(mSoundReceiver);         if(mArcApi!=null)             mArcApi.onReleaseFT();        System.exit(0);    }    private BroadcastReceiver mSoundReceiver = new BroadcastReceiver() {        public void onReceive(Context context, Intent intent) {            Log.d(TAG,"STRIKE_HEAD    "+STRIKE_HEAD+" action name   "+intent.getAction());            String action = intent.getAction();            if(!STRIKE_HEAD){                //SOVLE TO CLIENT CLICK APPLICATION TRANSITION BEGINNING                if (action.equals(StaticValue.ACTION_UBT_APP_EXIT)) {                    String appinfo=intent.getStringExtra("PACKAGENAME");                    Log.d(TAG,"RECEIVE THE APP EXIT BROADCAST      "+appinfo);                    if(appinfo.equals("com.ubtech.smartcamera")) {                        SmartCameraActivity.this.finish();                    }                }                return;            }            if (action.equals(ALPHA_SPEECH_DIRECTION)) {                Log.d(TAG, "Sound detection, so control_head_angle angle" + intent.getByteExtra("absoluteAngle", (byte) 0) + "currentAngle" + intent.getByteExtra("angle", (byte) 0));                Bundle extras = intent.getExtras();                if (extras != null) {                    if (status == SOUND_DETECTION) {                        byte mUserAngle = intent.getByteExtra("absoluteAngle", (byte) 0);                        Log.d(TAG, "mUserAngle :" + mUserAngle + "   mLastUserAngle : " + mLastUserAngle + "times  " + find_sound_times);                        if (mUserAngle != mLastUserAngle) {                            Log.d(TAG, "step one FINING SOUND");                           // processAngle(FACE_HORIZONAL_ANGLE, mUserAngle, 125);                            mLastUserAngle = mUserAngle;                            //After 5s to exit the timer                            Log.d(TAG, "step two FINING SOUND");                            mTimer.cancel();                            mTimerTask.cancel();                            find_sound_times = 0;                        }                        Log.d(TAG, "step step one " + mUserAngle);                    }                }            } else if (intent.getAction().equals(UBTEK_KEY_BROADCAST)) {                byte keyValue = (byte) intent.getByteExtra(UBTEK_KEY_VALUE, (byte) 6);                Log.d(TAG, "EXIT THE APP keyValue"+keyValue);                if (keyValue == 6) {                       mHandler.sendEmptyMessage(EXIT_PHOTO_MODE_HITHEAD);                }            }if (action.equals(StaticValue.ACTION_UBT_APP_EXIT)) {                String packageName = intent.getStringExtra("PACKAGENAME");                Log.i(TAG,"EXIT PACKAGEName:"+packageName+"  pn="+getPackageName());                if(packageName.equals(getPackageName())) {                    SmartCameraActivity.this.finish();                }            }        }    };    private void findUserSoundLocation() {        mTimer = new Timer();        mTimerTask = new TimerTask() {            @Override            public void run() {                find_sound_times++;                if (find_sound_times >= DETECT_SOUND_TIME) {                    mTimer.cancel();                    mTimerTask.cancel();                    mHandler.sendEmptyMessage(NOT_FINDING_SOUND);                    find_sound_times = 0;                }            }        };        mTimer.schedule(mTimerTask, 10, 1000);    }    private void stopFindingSoundTimer() {        mTimer.cancel();        mTimerTask.cancel();        find_sound_times = 0;    }    private void findUserFaceLocation() {        mTimer1 = new Timer();        mTimerTask1 = new TimerTask() {            @Override            public void run() {                find_face_times++;                if (find_face_times >= DETECT_FACE_TIME) {                    mTimer1.cancel();                    mTimerTask1.cancel();                    mHandler.sendEmptyMessage(NOT_FINDING_FACE);                    find_face_times = 0;                }            }        };        mTimer1.schedule(mTimerTask1, 10, 1000);    }    private void stopFindUserFaceTimer() {        if(mTimer1!=null)            mTimer1.cancel();        if(mTimerTask1!=null)            mTimerTask1.cancel();        find_face_times = 0;    }    private void processAngle(int anglestatus, int xAngle, int yAngle) {        Log.d(TAG, "!!!!!!! processAngle x=" + xAngle + "y=   " + yAngle + "  type  " + anglestatus);        if (xAngle < 0) {            xAngle = 256 + xAngle;        }        if (anglestatus == INIT_ANGLE) {            motionRobotApi.moveToAbsoluteAngle((byte) 19,xAngle,single_time ,null );            try {                Thread.sleep(200);            } catch (Exception e) {            }            motionRobotApi.moveToAbsoluteAngle((byte) 20,yAngle, single_time,null );        } else if (anglestatus == FACE_HORIZONAL_ANGLE) {            motionRobotApi.moveToAbsoluteAngle((byte) 19,xAngle, single_time,null );        } else if (anglestatus == FACE_VERTICAL_ANGLE) {            motionRobotApi.moveToAbsoluteAngle((byte) 20,yAngle, single_time,null );        }        if (anglestatus == FACE_HORIZONAL_VERTICAL_ANGLE) {            //TODO use the following method, cause navigation long time            motionRobotApi.moveToAbsoluteAngle((byte) 19,xAngle, single_time,null );            motionRobotApi.moveToAbsoluteAngle((byte) 20,yAngle, single_time,null );        }    }    public void initRobot() {        mRobot =AlphaRobotApi.get();        mRobot.initializ(this);        speechApi= SpeechRobotApi.get();        speechApi.initializ(this);        ledRobotApi=LedRobotApi.get();        ledRobotApi.initializ(this);        motionRobotApi= MotionRobotApi.get().initializ(this);    }    public void initOver() {        initServo();        if (!StorageUtil.isAvailableExternalMemoryGreaterThan100M()) {            mHandler.sendEmptyMessage(STORAGE_SPACE_LESS);            Log.d(TAG,"storage space less ");        } else {            mHandler.sendEmptyMessage(ENTER_PHOTO_MODE);            Log.d(TAG,"storage space more");        }    }    private void initServo() {        dataAngle = new int[20];        for (int i = 0; i < 20; i++) {            if (i == 18) {// 头部19号                dataAngle[i] = 90;// 1-249 正常状态 是120度            } else if (i == 19) {// 头部20号 正常状态 是120度                dataAngle[i] = 135;// //保持舵机不动            } else {// 其他舵机                dataAngle[i] = 250;// 保持舵机不动            }        }        processAngle(INIT_ANGLE, 120, 120);   //105 HEAD HIGH    }    private void initFaceEngine() {        Log.d(TAG, "initFace Engine");        mArcApi = new ArcSoftApi();        mArcApi.onInitFaceTrack();        mArcApi.onInitFaceRegister();        mArcApi.onSetFTModuleType(ArcConstants.DETECT_TYPE_FACE);    }    private void initViews() {        faceView = (FaceView) findViewById(R.id.face_view);        faceView.setHandler(mHandler);        faceView.setCallBack(this);        preview = (CameraPreview) findViewById(R.id.preview);        preview.setCallBack(this);        preview.setHandler(mHandler);        preview.setFaceView(faceView);    }    private Handler mHandler = new Handler() {        @Override        public void handleMessage(Message msg) {            Log.d(TAG, "RECEIVE THE MESSAGE   " + msg.what +"   status  "+status);            if (msg.what >= status) {                status = msg.what;            } else {                Log.d(TAG, "NOT DEAL RECEIVE THE MESSAGE   " + msg.what);                return;            }           int value = 0;            String text = null;            Random random = new Random();            switch (status) {                case STORAGE_SPACE_LESS:                    this.postDelayed(new Runnable() {                        @Override                        public void run() {                            STRIKE_HEAD=true;                            int index = new Random().nextInt(2);                            String text = StringUtil.getString(R.string.storage_less_100_0 + index);                            speechApi.speechStartTTS(text, new SpeechTtsListener() {                                @Override                                public void onEnd() {                                    KillProcess();                                }                            });                        }                    },5000);                    break;                case ENTER_PHOTO_MODE:                    this.postDelayed(new Runnable() {                        @Override                        public void run() {                            STRIKE_HEAD=true;                            int index =   new Random().nextInt(2);                            String text0 = StringUtil.getString(R.string.storage_more_100_0 + index);                            Log.d("TAG", "ENTER_PHOTO_MODE ");                            speechApi.speechStartTTS(text0, new SpeechTtsListener() {                                @Override                                public void onEnd() {                                    LedRobotApi.get().turnOnEyeFlash(LedColor.BLUE, LedBright.NINE, new LedOperationResultListener() {                                        @Override                                        public void onLedOpResult(int opId, int nErr) {                                        }                                    });                                    mHandler.sendEmptyMessage(SOUND_DETECTION);                                }                            });                        }                    },5000);                    break;                case SOUND_DETECTION:                    Log.d("TAG", "SOUND_DETECTION ");                    mHandler.sendEmptyMessage(FACE_DETECTION);                    break;                case NOT_FINDING_SOUND:                    Log.d("TAG", "NOT_FINDING_SOUND ");                    value = random.nextInt(4);                    text = StringUtil.getString(R.string.sound_invalid_domain_0 + value);                    speechApi.speechStartTTS(text, new SpeechTtsListener() {                        @Override                        public void onEnd() {                            mHandler.sendEmptyMessage(FACE_DETECTION);                        }                    });                    break;                case FINDING_SOUND:                    Log.d("TAG", "FINDING_SOUND ");                    stopFindingSoundTimer();                    text = StringUtil.getString(R.string.enter_face_detection);                    speechApi.speechStartTTS(text, new SpeechTtsListener() {                        @Override                        public void onEnd() {                            try {                                Thread.sleep(3000);                            } catch (Exception e) {                            }                            mHandler.sendEmptyMessage(FACE_DETECTION);                        }                    });                    break;                case FACE_DETECTION:                    Log.d("TAG", "FACE_DETECTION ");                    findUserFaceLocation();                    break;                case NOT_FINDING_FACE:                    Log.d("TAG", "NOT_FINDING_FACE ");                    text = StringUtil.getString(R.string.not_found_face);                    speechApi.speechStartTTS(text, new SpeechTtsListener() {                        @Override                        public void onEnd() {                            confirm_times = 0;                            stopFindUserFaceTimer();                            faceView.TimerCancelSendVerticalAngle();                            faceView.TimerCancelSendHorizontalAngle();                            processAngle(INIT_ANGLE, 120, 120);                            KillProcess();                        }                    });                    break;                case FINDING_FACE:                    Log.d("TAG", "FINDING_FACE ");                    stopFindUserFaceTimer();                    value = random.nextInt(2);                    text = StringUtil.getString(R.string.detection_face_0 + value);                    speechApi.speechStartTTS(text, new SpeechTtsListener() {                        @Override                        public void onEnd() {                            mHandler.sendEmptyMessage(START_TAKE_PHOTO);                        }                    });                    //TODO COMMENT THE FOLLOWING SENTENCES                    break;                case START_TAKE_PHOTO:                    Log.d("TAG", "START_TAKE_PHOTO ");                    preview.takePicture();                    break;                case PLAY_CAMERA_SOUND:                    playMusic("pose.mp3");                    break;                case SUCCESS_TAKE_PHOTO:                    processAngle(INIT_ANGLE, 120, 120);                    Log.d("TAG", "SUCCESS_TAKE_PHOTO ");                    value = random.nextInt(3);                    text = StringUtil.getString(R.string.take_photo_completion_0 + value);                    speechApi.speechStartTTS(text, new SpeechTtsListener() {                        @Override                        public void onEnd() {                            LedRobotApi.get().turnOffEyeFlash(null);                            mHandler.sendEmptyMessage(SmartCameraActivity.EXIT_PHOTO_MODE);                        }                    });                    break;                case EXIT_PHOTO_MODE:                    Log.d(TAG, "exit_photo_mode");                    try{                        Thread.sleep(3000);                    }catch(Exception e){                    }                    KillProcess();                    break;                case KILL_SELF:                    SmartCameraActivity.this.finish();                    break;                case EXIT_PHOTO_MODE_HITHEAD:                    stopFindUserFaceTimer();                    faceView.TimerCancelSendVerticalAngle();                    faceView.TimerCancelSendHorizontalAngle();                    String exittext = StringUtil.getString(R.string.exit_smartphoto);                    speechApi.speechStartTTS(exittext, new SpeechTtsListener() {                        @Override                        public void onEnd() {                            status=EXIT_SMART_CAMERA;                            try{                                Thread.sleep(3000);                            }catch(Exception e){                            }                            speechApi.speechStopTTS();                            processAngle(INIT_ANGLE, 120, 120);                            KillProcess();                        }                    });                    break;                default:                    break;            }        }    };    private void playMusic(String musicName) {        if (musicName == null) {            return;        }        Log.d(TAG, "MUSIC PATH" + musicName);        try {            AssetManager am = mContext.getAssets();// 获得该应用的AssetManager            AssetFileDescriptor afd = am.openFd(musicName);            MediaPlayer  player = new MediaPlayer();            player.setDataSource(afd.getFileDescriptor());            player.prepare();            player.start();            player.setOnCompletionListener(new MediaPlayer.OnCompletionListener() {                public void onCompletion(MediaPlayer mp) {                    mp.release();                }            });        } catch (IOException e) {            e.printStackTrace();        }    }    /**     * 成功检测到人脸的回调，可以做相应的操作     */    private OnDetectCallback mDetectCallback = new OnDetectCallback() {        @Override        public void onResult(ArcDetectResult result) {            if (result.getFaceRects() == null) {                return;            }            Rect[] faceRects = result.getFaceRects();            RectfVector mFaceVector = new RectfVector();            ArcsoftDetectionRectF[] mFaceRect = new ArcsoftDetectionRectF[result.getFaceNum()];            for (int i = 0; i < result.getFaceNum(); i++) {                Rect rect = faceRects[i];                ArcsoftDetectionRectF faceRect = new ArcsoftDetectionRectF();                faceRect.setBottom(rect.bottom);                faceRect.setLeft(rect.left);                faceRect.setRight(rect.right);                faceRect.setTop(rect.top);                mFaceRect[i] = faceRect;            }            mFaceVector.setmFaceRect(mFaceRect);            faceView.setFaces(mFaceVector);        }    };    /**     * Receive the alpha2servcie broadcast to exit the app     */    class ExitBrocast extends BroadcastReceiver {        @Override        public void onReceive(Context context, Intent intent) {            if (intent.getAction().equals(StaticValue.ACTION_UBT_APP_EXIT)) {                Log.d(TAG, "RECEIVE THE SYSTEM BROADCAST EXIT EXIT !!!");                mRobot.destroy();                mRobot = null;                System.exit(0);            }        }    }    @Override    public void onRobotAngle(int type,int x, int y) {        if(status==FACE_DETECTION) {          //  processAngle(type, x, y);        }    }    @Override    public void onTTS(int result) {        // TODO Auto-generated method stub        if (mPoseState == PoseState.IDLE) {            mPoseState = PoseState.PLAYING;            Log.i("Pose", "" + mPoseState);            //	String text = this.getString(R.string.start_pose);            //	mRobot.speech_StartTTS(text);        }    }    @Override    public void onDetectFace(ByteBuffer data, int width, int height){        // TODO Auto-generated method stub     //   Log.d(TAG,"TEST CALL BACK ");        if(mArcApi!=null)        mArcApi.onFaceDetect(data, mDetectCallback,width,height);    }    private void KillProcess(){        Intent intent = new Intent(ALPHA_APP_MANAGE);        Bundle bundle = new Bundle();        bundle.putString("appevent", "start");        bundle.putString("packageName",SmartCameraActivity.defApp);        bundle.putString("name", "");        bundle.putString("clientIP", "");        bundle.putString("srcApp", mContext.getPackageName());        bundle.putByte("angle", (byte)250);        intent.putExtras(bundle);        mContext.sendBroadcast(intent);        mHandler.sendEmptyMessageDelayed(KILL_SELF ,3000);    }}